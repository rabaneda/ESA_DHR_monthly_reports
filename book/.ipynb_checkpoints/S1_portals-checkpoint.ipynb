{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864c298b",
   "metadata": {},
   "source": [
    "# Sentinel-1 products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8d509",
   "metadata": {},
   "source": [
    "This section shows the performance of MET Norway DHR for Sentinel-1 products. Both, an overall status and last month status are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f6f1c3-9fc5-4e77-b99c-cd48bf5062d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import copy\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5acf2383-aa77-4176-ae7f-4584cf4e4b66",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "#logsdir = pathlib.Path('/lustre/storeB/project/NBS2/sentinel/production/NorwAREA/netCDFNBS_work/production/monitoring/dhus_queries')\n",
    "logsdir = pathlib.Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3a8f7-271a-43ed-9469-2c5b79c2add5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_stats(df, plot_max=False, plot_BE=True):\n",
    "\n",
    "    fig, ax = plt.subplots()  \n",
    "\n",
    "    #color1 = 'xkcd:sea blue'\n",
    "    color2 = 'xkcd:brick red'\n",
    "    color3 = 'xkcd:olive green'\n",
    "    color4 = 'xkcd:gold'\n",
    "    color5 = 'xkcd:sea blue'\n",
    "\n",
    "    plt.plot(df.index, df['scihub'], linestyle='solid', color=color2, label='scihub.copernicus.eu')\n",
    "    plt.plot(df.index, df['colhub_global'], linestyle='solid', color=color3, label='colhub.met.no')\n",
    "    if not df['esahub_global'].isnull().all() and not (df['esahub_global'] == 0).all():\n",
    "        plt.plot(df.index, df['esahub_global'], linestyle='solid', color=color4, label='sentinelhub2.met.no')\n",
    "    if not (df['colhub_AOI'] == 0).all():\n",
    "        plt.plot(df.index, df['colhub_AOI'], linestyle='solid', color=color4, label='colhub-archive.met.no')\n",
    "    if 'BE' in df and plot_BE:\n",
    "        plt.plot(df.index, df['BE'], linestyle='solid', color=color5, label='MET Norway BE')\n",
    "    \n",
    "    if plot_max == True:\n",
    "        days = [1]\n",
    "    elif plot_max == False:\n",
    "        days = [1,10,20]\n",
    "    \n",
    "    ax.set_ylabel('Number of products per sensing day')\n",
    "    ax.tick_params('y')\n",
    " \n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "    #ax.xaxis.set_minor_formatter(mdates.DateFormatter('%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=days))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b'))\n",
    "    ax.tick_params(axis='x', rotation=70)\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfb42ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_missing(df, plot_max=False):\n",
    "    \n",
    "    # Number of missing products\n",
    "    missing_all = int(sum(df['scihub'] - df['colhub_global']))\n",
    "    missing_perc_all = ((df['scihub'] - df['colhub_global'])/df['scihub'])\n",
    "    \n",
    "    missing_30 = int(sum((df['scihub'] - df['colhub_global']).iloc[-30]))\n",
    "    missing_perc_30 = ((df['scihub'] - df['colhub_global'])/df['scihub']).iloc[-30]\n",
    "    \n",
    "    #missing_1 = int((df['scihub'] - df['colhub_global']).iloc[-1])\n",
    "    #missing_perc_1 = ((df['scihub'] - df['colhub_global'])/df['scihub']).iloc[-1]\n",
    "    \n",
    "    plt.figtext(-0.4,0.3, 'Difference between \\nscihub and colhub \\n (last day) \\n\\n {:d} products missing \\n\\n ~{:.1%} of the products'.format(missing, missing_perc, 1/3), color=color2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3645d550-3108-4700-bf39-0d6ab0c0099e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "hubs=['colhub_global', 'scihub', 'esahub_global', 'colhub_AOI']\n",
    "products=['S1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d1456-875c-4032-9503-63a4204d981c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_FE = None\n",
    "for h in hubs:\n",
    "    csvfile = logsdir / f'products_in_{h}.csv'\n",
    "    data_tmp = pd.read_csv(csvfile, header=None, names=['product', 'area', 'sensing_date', f'{h}'], parse_dates=['sensing_date'])\n",
    "    # If several sensing date exist, keep the most recent one\n",
    "    data_clean = copy.deepcopy(data_tmp.drop_duplicates(subset=['sensing_date', 'product', 'area'], keep='last'))\n",
    "    if h == 'colhub_AOI':\n",
    "        data_clean['area'] = 'colhub_aoi'\n",
    "    if data_FE is None:\n",
    "        data_FE = data_clean\n",
    "    else:\n",
    "        data_FE = data_FE.merge(data_clean, on=['sensing_date', 'product', 'area'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630055b3-e5bc-4130-bc7a-688fe6111b18",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_BE = None\n",
    "areas = ['global', 'AOI']\n",
    "products=['S1']\n",
    "for a in areas:\n",
    "    for p in products:\n",
    "        csvfile = logsdir / f'products_in_BE_{p}_{a}.csv'\n",
    "        data_tmp = pd.read_csv(csvfile, header=None, names=['product', 'area', 'sensing_date', 'BE'], parse_dates=['sensing_date'])\n",
    "        # If several sensing date exist, keep the most recent one\n",
    "        data_clean = copy.deepcopy(data_tmp.drop_duplicates(subset=['sensing_date', 'product', 'area'], keep='last'))\n",
    "        if a == 'AOI':\n",
    "            data_clean['area'] = 'colhub_aoi'\n",
    "        if data_BE is None:\n",
    "            data_BE = data_clean\n",
    "        else:\n",
    "            data_BE = data_BE.append(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea14ff2-54eb-4cd1-bc12-e9bebbacd788",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data = data_FE.merge(data_BE, on=['sensing_date', 'product', 'area'], how='outer')\n",
    "# 2022-04-07 - BE are now in more secure network so unavailable for direct queries, so only check FE data\n",
    "#data = data_FE\n",
    "data.set_index('sensing_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "#print(data.loc[data.index >= (dt.datetime.today() - dt.timedelta(days=2))].sort_values(['area', 'product'], axis=0, ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2ac575",
   "metadata": {},
   "source": [
    "## Products on portals\n",
    "\n",
    "The following section contains an update on the Sentinel-1 products included in the different FEs and BEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0033c7-3597-48b9-9f0e-0a70c48851f7",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "mask = (data['product'] == 'S1') & (data['area'] == 'global')\n",
    "plot_stats(data.loc[mask], plot_max = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8baba",
   "metadata": {},
   "source": [
    "The figure above represents the overall number of products present in the different BackEnds and FrontEnds per day for Sentinel-1.\n",
    "\n",
    "While the figure below shows a zoom on the last 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7f541",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "latest = data.loc[mask][data.loc[mask].index >= (dt.datetime.today() - dt.timedelta(days=30))]\n",
    "#print('Zoom on the last 30 days')\n",
    "plot_stats(latest, plot_max = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0529f",
   "metadata": {},
   "source": [
    "A 30 days table is also included for more detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9282e2",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_c = data.loc[mask][-30:][['colhub_global', 'scihub', 'esahub_global', 'BE']].copy()\n",
    "data_c.rename(inplace=True, columns={'colhub_global':'colhub.met.no', 'scihub':'scihub.copernicues.eu', 'esahub_global':'sentinelhub2.met.no', 'BE':'MET Norway BE'})\n",
    "data_c\n",
    "# S1 colhub global FE has more data than esahub global FE and the BE as it contains the KSAT data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab130c8",
   "metadata": {},
   "source": [
    "## Missing products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f194f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Number of missing products\n",
    "total_all = int(sum(data['scihub']))\n",
    "missing_all = int(sum(data['scihub'] - data['colhub_global']))\n",
    "included_perc_all = int(sum(data['colhub_global'])/sum(data['scihub']))*100\n",
    "missing_perc_all = 100 - included_perc_all\n",
    "\n",
    "total_30 = int(sum(data['scihub'].iloc[:-30]))\n",
    "missing_30 = int(sum(data['scihub'].iloc[:-30] - data['colhub_global'].iloc[:-30]))\n",
    "included_perc_30 = int(sum(data['colhub_global'].iloc[:-30])/sum(data['scihub'].iloc[:-30]))*100\n",
    "missing_perc_30 = 100 - included_perc_30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaf587",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(\"The overall total number of Sentinel-1 products is {}. The number of overall Sentinel-1 missing products consists of {} images. This represents that a {}% of the total was included in MET Norway DHR, while a {}% was not included.\".format(total_all, missing_all, included_perc_all, missing_perc_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a7b5e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "md(\"The total number of Sentinel-1 products in the last 30 days is {}. The number of Sentinel-1 missing products during the last 30 days consists of {} images. This represents that a {}% of the total was included in MET Norway DHR, while a {}% was not included.\".format(total_30, missing_30, included_perc_30, missing_perc_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20d49a",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abf681",
   "metadata": {},
   "source": [
    "In this section the time difference between sensing time and ingestion time at MET norway is assessed. The ingestion time is the time at which a Sentinel product was downloaded to MET Norway BE and so, it is automatically available in at least one of the MET Norway FEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc6465",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def read_dhus_logs(file):\n",
    "    data = pd.read_csv(file, header=None, names=['day', 'product_type', 'action', 'size', 'number', 'timeliness']\\\n",
    "                        , parse_dates=['day'])    \n",
    "    out = {}\n",
    "    for type in ['synchronized', 'deleted', 'fscanner']:\n",
    "        d = data[data['action'] == type].drop('action', 1)\n",
    "        stats_1 = d.groupby(['day']).sum()[['size', 'number']]\n",
    "        stats_2 = d.groupby(['day']).median()['timeliness']\n",
    "        stats = stats_1.join(stats_2)\n",
    "        if len(stats) > 0:\n",
    "            stats = stats.asfreq('1D', fill_value=0)\n",
    "        out.update({type: stats})\n",
    "    #if out['synchronized'].index[-1] != (pd.Timestamp.today().date()  - pd.Timedelta(days=1)):\n",
    "     #   print('WARNING!!! No data synchronized yesterday!?')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b8edf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def read_dhus_logs_details(file):\n",
    "    data = pd.read_csv(file, header=None, names=['day', 'product_type', 'action', 'size', 'number', 'timeliness']\\\n",
    "                        , parse_dates=['day'], index_col=['day'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5796a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_stats_logs(synchronized, deleted=None, fscanner=None, plot_max=False):\n",
    "   \n",
    "    # Simple stats that will be annotations on the plot\n",
    "    median = int(synchronized['number'].iloc[0:-2].median())\n",
    "    last = int(synchronized['number'].iloc[-1])\n",
    "    t_median = synchronized['timeliness'].iloc[0:-2].median()\n",
    "    t_last = synchronized['timeliness'].iloc[-1]\n",
    "    if fscanner is not None:\n",
    "        fmedian = int(fscanner['number'].iloc[0:-2].median())\n",
    "        flast = int(fscanner['number'].iloc[-1])\n",
    "        ft_median = fscanner['timeliness'].iloc[0:-2].median()\n",
    "        ft_last = fscanner['timeliness'].iloc[-1]\n",
    "\n",
    "    fig, ax = plt.subplots()  \n",
    "\n",
    "    color1 = 'xkcd:sea blue'\n",
    "    color2 = 'xkcd:brick red'\n",
    "    color3 = 'xkcd:light blue'\n",
    "\n",
    "    # Plot timeliness\n",
    "    plt.plot(synchronized.index, synchronized['timeliness'], linestyle='solid', color=color2)\n",
    "    ax.set_ylim([0, None]) \n",
    "    ax.set_ylabel('Timeliness in hours', color=color2)\n",
    "    ax.tick_params('y', colors=color2)\n",
    "    #plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    # Plot number of products\n",
    "    ax2 = ax.twinx()\n",
    "    plt.plot(synchronized.index, synchronized['number'], color=color1, label='synchronized')\n",
    "    if fscanner is not None:\n",
    "        plt.plot(fscanner.index, fscanner['number'], linestyle='dashed', color=color1, label='fscanned')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "    if deleted is not None:\n",
    "        plt.plot(deleted.index, deleted['number'], color=color3, label='deleted')\n",
    "    plt.legend(loc=\"best\")\n",
    "    ax2.set_xlabel('Ingestion date in colhub')\n",
    "    ax2.set_ylabel('Number of products', color=color1)\n",
    "    ax2.tick_params('y', colors=color1)\n",
    "\n",
    "    # Add statistics\n",
    "    #plt.figtext(-0.4,0.8, f'Synchronizers')\n",
    "    #plt.figtext(-0.4,0.6, 'Timeliness (in hours) \\n\\n last day {:5.2f} \\n median {:5.2f}'.format(t_last, t_median), color=color2)\n",
    "    #plt.figtext(-0.4,0.4, f'Number of products ingested \\n\\n last day {last} \\n median {median}', color=color1)\n",
    "    #if fscanner is not None:\n",
    "     #   plt.figtext(1.2,0.8, f'Fscanners')\n",
    "      #  plt.figtext(1.2,0.6, 'Timeliness (in hours) \\n\\n last day {:5.2f} \\n median {:5.2f}'.format(ft_last, ft_median), color=color2)\n",
    "       # plt.figtext(1.2,0.4, f'Number of products ingested \\n\\n last day {flast} \\n median {fmedian}', color=color1)\n",
    "    \n",
    "    \n",
    "    # Time axis formatting\n",
    "    if plot_max == True:\n",
    "        days = [1]\n",
    "    elif plot_max == False:\n",
    "        days = [1,10,20]\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "    #ax.xaxis.set_minor_formatter(mdates.DateFormatter('%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=days))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe02e28",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_stats_logs_daily(synchronized, deleted=None, fscanner=None, plot_max=False):\n",
    "   \n",
    "    # Simple stats that will be annotations on the plot\n",
    "    median = int(synchronized['number'].iloc[0:-2].median())\n",
    "    last = int(synchronized['number'].iloc[-1])\n",
    "    t_median = synchronized['timeliness'].iloc[0:-2].median()\n",
    "    t_last = synchronized['timeliness'].iloc[-1]\n",
    "    if fscanner is not None:\n",
    "        fmedian = int(fscanner['number'].iloc[0:-2].median())\n",
    "        flast = int(fscanner['number'].iloc[-1])\n",
    "        ft_median = fscanner['timeliness'].iloc[0:-2].median()\n",
    "        ft_last = fscanner['timeliness'].iloc[-1]\n",
    "\n",
    "    fig, ax = plt.subplots()  \n",
    "\n",
    "    color1 = 'xkcd:sea blue'\n",
    "    color2 = 'xkcd:brick red'\n",
    "    color3 = 'xkcd:light blue'\n",
    "\n",
    "    # Plot timeliness\n",
    "    plt.plot(synchronized.index, synchronized['timeliness'], linestyle='solid', color=color2)\n",
    "    ax.set_ylim([0, None]) \n",
    "    ax.set_ylabel('Timeliness in hours', color=color2)\n",
    "    ax.tick_params('y', colors=color2)\n",
    "    #plt.legend(loc=\"lower left\")\n",
    "    \n",
    "    # Plot number of products\n",
    "    ax2 = ax.twinx()\n",
    "    plt.plot(synchronized.index, synchronized['number'], color=color1, label='synchronized')\n",
    "    if fscanner is not None:\n",
    "        plt.plot(fscanner.index, fscanner['number'], linestyle='dashed', color=color1, label='fscanned')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "    if deleted is not None:\n",
    "        plt.plot(deleted.index, deleted['number'], color=color3, label='deleted')\n",
    "    plt.legend(loc=\"best\")\n",
    "    ax2.set_xlabel('Ingestion date in colhub')\n",
    "    ax2.set_ylabel('Number of products', color=color1)\n",
    "    ax2.tick_params('y', colors=color1)\n",
    "\n",
    "    # Add statistics\n",
    "    #plt.figtext(-0.4,0.8, f'Synchronizers')\n",
    "    #plt.figtext(-0.4,0.6, 'Timeliness (in hours) \\n\\n last day {:5.2f} \\n median {:5.2f}'.format(t_last, t_median), color=color2)\n",
    "    #plt.figtext(-0.4,0.4, f'Number of products ingested \\n\\n last day {last} \\n median {median}', color=color1)\n",
    "    #if fscanner is not None:\n",
    "     #   plt.figtext(1.2,0.8, f'Fscanners')\n",
    "      #  plt.figtext(1.2,0.6, 'Timeliness (in hours) \\n\\n last day {:5.2f} \\n median {:5.2f}'.format(ft_last, ft_median), color=color2)\n",
    "       # plt.figtext(1.2,0.4, f'Number of products ingested \\n\\n last day {flast} \\n median {fmedian}', color=color1)\n",
    "    \n",
    "    \n",
    "    # Time axis formatting\n",
    "    if plot_max == True:\n",
    "        days = [1]\n",
    "    elif plot_max == False:\n",
    "        days = [1,10,20]\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=days))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9b473",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_stats_simple(df, plot_max=False):\n",
    "\n",
    "    fig, ax = plt.subplots()  \n",
    "\n",
    "    color1 = 'xkcd:brick red'\n",
    "\n",
    "    # Plot nb of products\n",
    "    plt.plot(df.index, df['nb_products'], linestyle='solid', color=color1)\n",
    "    ax.set_ylim([0, None]) \n",
    "    ax.set_ylabel('Number of products', color=color1)\n",
    "    ax.tick_params('y', colors=color1)\n",
    "    \n",
    "    # Time axis formatting\n",
    "    if plot_max == True:\n",
    "        days = [1]\n",
    "    elif plot_max == False:\n",
    "        days = [1,10,20]\n",
    "    ax.xaxis.set_minor_locator(mdates.DayLocator())\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(bymonthday=days))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d63b393",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "#csvdir = pathlib.Path('/lustre/storeB/project/NBS2/sentinel/production/NorwAREA/netCDFNBS_work/production/monitoring/dhus_logs')\n",
    "csvdir = logsdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d10d20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data = read_dhus_logs(csvdir / 'S1-backend-global_inputs.csv')\n",
    "plot_stats_logs(data['synchronized'], deleted=data['deleted'], plot_max=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09305659",
   "metadata": {},
   "source": [
    "The figure above shows an overall status of the Sentinel-1 synchronization between ESA datahub and MET Norway BE. The number of products synchronized and deleted are represented by the dark and light blue lines respectively. The red line represents the timeliness.\n",
    "\n",
    "Following previous sections, the graph below shows a zoom in the last 30 days for the synchronization between ESA datahub and MET Norway BE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529ff27",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "latest = data['synchronized'][data['synchronized'].index >= (dt.datetime.today() - dt.timedelta(days=30))]\n",
    "#print('Zoom on the last 30 days')\n",
    "plot_stats_logs_daily(latest, plot_max=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b3715",
   "metadata": {},
   "source": [
    "A more detailed information is given in the table below where the last 30 days are assessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b490c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "#print('Numbers for the last 5 days')\n",
    "data['synchronized'].iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63bbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "002c83d4",
   "metadata": {},
   "source": [
    "## Key Performance Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac5d9a",
   "metadata": {},
   "source": [
    "This section is under construction"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
